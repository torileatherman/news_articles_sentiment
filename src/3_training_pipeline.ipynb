{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-15 17:27:26.353602: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import hopsworks\n",
    "import joblib\n",
    "import keras_tuner as kt\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from hsml.model_schema import ModelSchema\n",
    "from hsml.schema import Schema\n",
    "from huggingface_hub import notebook_login\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import (LSTM, Bidirectional, Dense, Dropout,\n",
    "                                     Embedding, GlobalMaxPooling1D)\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Hopsworks, Huggingface & WandB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/5322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "project = hopsworks.login() \n",
    "\n",
    "fs = project.get_feature_store() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "621b0e78ffd54d21a69eaa53e87339f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-15 17:27:41,746 ERROR: Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33meengel7\u001b[0m (\u001b[33mtwo_data_scientists\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Login to wandb\n",
    "wandb.login()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data from Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-15 17:27:47,687 WARNING: Using custom data configuration eengel7--sentiment_analysis_training-4fdc9da1d69f12bd\n",
      "2023-01-15 17:27:47,783 WARNING: Found cached dataset parquet (/Users/evaengel/.cache/huggingface/datasets/eengel7___parquet/eengel7--sentiment_analysis_training-4fdc9da1d69f12bd/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"eengel7/sentiment_analysis_training\", split='train')\n",
    "data_df = pd.DataFrame(data = ds, columns=['Sentiment',  'Headline'])\n",
    "\n",
    "y = pd.get_dummies(data_df['Sentiment'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(pd.DataFrame(data_df['Headline'].to_list()),y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing & Model params\n",
    "voc_size = 5000 \n",
    "max_len = 60\n",
    "embedding_vector_features = 40\n",
    "\n",
    "# Training params\n",
    "epochs = 20\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1600scf7) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">rosy-monkey-1</strong>: <a href=\"https://wandb.ai/two_data_scientists/sentiment_analysis/runs/1600scf7\" target=\"_blank\">https://wandb.ai/two_data_scientists/sentiment_analysis/runs/1600scf7</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230115_172749-1600scf7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:1600scf7). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95580e71be6d4c89a1bae29de25fc771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01671273005000001, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/evaengel/news_articles_sentiment/src/wandb/run-20230115_172813-lc8a9xav</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/two_data_scientists/sentiment_analysis/runs/lc8a9xav\" target=\"_blank\">proud-rain-2</a></strong> to <a href=\"https://wandb.ai/two_data_scientists/sentiment_analysis\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project='sentiment_analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(     #EarlyStopping is used to stop at the epoch where val_accuracy does not improve significantly\n",
    "        monitor='val_accuracy',\n",
    "        min_delta=1e-4,\n",
    "        patience=4,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        filepath='weights.h5',\n",
    "        monitor='val_accuracy', \n",
    "        mode='max', \n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    WandbCallback()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypertuning the model\n",
    "def model_builder(hp):\n",
    "      '''\n",
    "      Args:\n",
    "      hp - Keras tuner object\n",
    "      '''\n",
    "      model = Sequential()\n",
    "      model.add(Embedding(voc_size,embedding_vector_features,input_length = max_len))\n",
    "      model.add(Bidirectional(LSTM(128, return_sequences=True))) \n",
    "      model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "      model.add(GlobalMaxPooling1D()) #Pooling Layer decreases sensitivity to features, thereby creating more generalised data for better test results.\n",
    "      model.add(Dense(1024))\n",
    "      model.add(Dropout(0.25)) #Dropout layer nullifies certain random input values to generate a more general dataset and prevent the problem of overfitting.\n",
    "      model.add(Dense(512))\n",
    "      model.add(Dropout(0.25))\n",
    "      model.add(Dense(256))\n",
    "      model.add(Dropout(0.25))\n",
    "      model.add(Dense(128))\n",
    "      model.add(Dropout(0.25))\n",
    "      model.add(Dense(64))\n",
    "      model.add(Dropout(0.25))\n",
    "      model.add(Dense(3, activation='softmax')) #softmax is used as the activation function for multi-class classification problems where class membership is required on more than two class labels.\n",
    "\n",
    "\n",
    "      # Tune the learning rate for the optimizer\n",
    "      # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "      hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "      model.compile(optimizer=Adam(learning_rate=hp_learning_rate),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "      return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-15 17:27:59,747 INFO: Reloading Oracle from existing project dir/ht_learning_rate/oracle.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-15 17:27:59.791905: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-15 17:28:01,302 INFO: Reloading Tuner from dir/ht_learning_rate/tuner0.json\n",
      "Search space summary\n",
      "Default search space size: 1\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the tuner\n",
    "tuner = kt.Hyperband(model_builder, # the hypermodel\n",
    "                    objective='val_accuracy', # objective to optimize\n",
    "                    directory='dir', # directory to save logs \n",
    "                    project_name='ht_learning_rate')\n",
    "\n",
    "# hypertuning settings\n",
    "tuner.search_space_summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-15 17:28:23,968 INFO: Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "# Perform hypertuning\n",
    "tuner.search(X_train, y_train, epochs=epochs, validation_data=(X_test, y_test), callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameter search is complete. The optimal learning rate for the optimizeris 0.001.\n"
     ]
    }
   ],
   "source": [
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"The hyperparameter search is complete. The optimal learning rate for the optimizeris {best_hps.get('learning_rate')}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 60, 40)            200000    \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 60, 256)          173056    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 60, 128)          164352    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Glo  (None, 128)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1024)              132096    \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,366,979\n",
      "Trainable params: 1,366,979\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.9867 - accuracy: 0.4934\n",
      "Epoch 1: val_accuracy improved from -inf to 0.60565, saving model to weights.h5\n",
      "2023-01-15 17:29:37,008 WARNING: Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses while saving (showing 5 of 9). These functions will not be directly callable after loading.\n",
      "2023-01-15 17:29:40,613 INFO: Assets written to: /Users/evaengel/news_articles_sentiment/src/wandb/run-20230115_172749-1600scf7/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/evaengel/news_articles_sentiment/src/wandb/run-20230115_172749-1600scf7/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 71s 2s/step - loss: 0.9867 - accuracy: 0.4934 - val_loss: 0.8080 - val_accuracy: 0.6057\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.6559 - accuracy: 0.7124\n",
      "Epoch 2: val_accuracy improved from 0.60565 to 0.68261, saving model to weights.h5\n",
      "2023-01-15 17:30:28,827 WARNING: Found untraced functions such as _update_step_xla, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses while saving (showing 5 of 9). These functions will not be directly callable after loading.\n",
      "2023-01-15 17:30:32,168 INFO: Assets written to: /Users/evaengel/news_articles_sentiment/src/wandb/run-20230115_172749-1600scf7/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/evaengel/news_articles_sentiment/src/wandb/run-20230115_172749-1600scf7/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 51s 1s/step - loss: 0.6559 - accuracy: 0.7124 - val_loss: 0.7109 - val_accuracy: 0.6826\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.4744 - accuracy: 0.8112\n",
      "Epoch 3: val_accuracy did not improve from 0.68261\n",
      "36/36 [==============================] - 28s 771ms/step - loss: 0.4744 - accuracy: 0.8112 - val_loss: 0.7536 - val_accuracy: 0.6761\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.3726 - accuracy: 0.8571\n",
      "Epoch 4: val_accuracy did not improve from 0.68261\n",
      "36/36 [==============================] - 29s 803ms/step - loss: 0.3726 - accuracy: 0.8571 - val_loss: 0.9644 - val_accuracy: 0.6661\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.2879 - accuracy: 0.8953\n",
      "Epoch 5: val_accuracy did not improve from 0.68261\n",
      "36/36 [==============================] - 28s 781ms/step - loss: 0.2879 - accuracy: 0.8953 - val_loss: 1.0394 - val_accuracy: 0.6591\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.2298 - accuracy: 0.9168\n",
      "Epoch 6: val_accuracy did not improve from 0.68261\n",
      "36/36 [==============================] - 28s 787ms/step - loss: 0.2298 - accuracy: 0.9168 - val_loss: 1.3025 - val_accuracy: 0.6561\n",
      "Epoch 6: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x138aab250>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit Model\n",
    "\n",
    "    # Build the model with the optimal hyperparameters\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "model.summary()\n",
    "\n",
    "model.fit(X_train, \n",
    "          y_train, \n",
    "          batch_size = batch_size, \n",
    "          validation_data=(X_test, y_test), \n",
    "          epochs = epochs, \n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▅▆▇██</td></tr><tr><td>epoch</td><td>▁▂▄▅▇█</td></tr><tr><td>loss</td><td>█▅▃▂▂▁</td></tr><tr><td>val_accuracy</td><td>▁█▇▆▆▆</td></tr><tr><td>val_loss</td><td>▂▁▂▄▅█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.91685</td></tr><tr><td>best_epoch</td><td>1</td></tr><tr><td>best_val_loss</td><td>0.71087</td></tr><tr><td>epoch</td><td>5</td></tr><tr><td>loss</td><td>0.22976</td></tr><tr><td>val_accuracy</td><td>0.65609</td></tr><tr><td>val_loss</td><td>1.30248</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">proud-rain-2</strong>: <a href=\"https://wandb.ai/two_data_scientists/sentiment_analysis/runs/lc8a9xav\" target=\"_blank\">https://wandb.ai/two_data_scientists/sentiment_analysis/runs/lc8a9xav</a><br/>Synced 5 W&B file(s), 1 media file(s), 9 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230115_172813-lc8a9xav/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Close W&B run\n",
    "wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_schema = Schema(X_train)\n",
    "output_schema = Schema(y_train)\n",
    "model_schema = ModelSchema(input_schema, output_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......bidirectional\n",
      ".........backward_layer\n",
      "............cell\n",
      "...............vars\n",
      "..................0\n",
      "..................1\n",
      "..................2\n",
      "............vars\n",
      ".........forward_layer\n",
      "............cell\n",
      "...............vars\n",
      "..................0\n",
      "..................1\n",
      "..................2\n",
      "............vars\n",
      ".........layer\n",
      "............cell\n",
      "...............vars\n",
      "............vars\n",
      ".........vars\n",
      "......bidirectional_1\n",
      ".........backward_layer\n",
      "............cell\n",
      "...............vars\n",
      "..................0\n",
      "..................1\n",
      "..................2\n",
      "............vars\n",
      ".........forward_layer\n",
      "............cell\n",
      "...............vars\n",
      "..................0\n",
      "..................1\n",
      "..................2\n",
      "............vars\n",
      ".........layer\n",
      "............cell\n",
      "...............vars\n",
      "............vars\n",
      ".........vars\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_4\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_5\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dropout\n",
      ".........vars\n",
      "......dropout_1\n",
      ".........vars\n",
      "......dropout_2\n",
      ".........vars\n",
      "......dropout_3\n",
      ".........vars\n",
      "......dropout_4\n",
      ".........vars\n",
      "......embedding\n",
      ".........vars\n",
      "............0\n",
      "......global_max_pooling1d\n",
      ".........vars\n",
      "...metrics\n",
      "......mean\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......mean_metric_wrapper\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........15\n",
      ".........16\n",
      ".........17\n",
      ".........18\n",
      ".........19\n",
      ".........2\n",
      ".........20\n",
      ".........21\n",
      ".........22\n",
      ".........23\n",
      ".........24\n",
      ".........25\n",
      ".........26\n",
      ".........27\n",
      ".........28\n",
      ".........29\n",
      ".........3\n",
      ".........30\n",
      ".........31\n",
      ".........32\n",
      ".........33\n",
      ".........34\n",
      ".........35\n",
      ".........36\n",
      ".........37\n",
      ".........38\n",
      ".........39\n",
      ".........4\n",
      ".........40\n",
      ".........41\n",
      ".........42\n",
      ".........43\n",
      ".........44\n",
      ".........45\n",
      ".........46\n",
      ".........47\n",
      ".........48\n",
      ".........49\n",
      ".........5\n",
      ".........50\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-01-15 17:44:48         6798\n",
      "metadata.json                                  2023-01-15 17:44:48           64\n",
      "variables.h5                                   2023-01-15 17:44:48     16492456\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['headlines_sentiment_model/headlines_sentiment_model.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr = project.get_model_registry()\n",
    "\n",
    "model_dir=\"headlines_sentiment_model\"\n",
    "if os.path.isdir(model_dir) == False:\n",
    "    os.mkdir(model_dir)\n",
    "\n",
    "joblib.dump(model, model_dir + \"/headlines_sentiment_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines_sentiment_model = mr.python.create_model(\n",
    "        name = \"headlines_sentiment_model\", \n",
    "        model_schema=model_schema,\n",
    "        description=\"Predicting Sentiment of Headlines\",\n",
    "        version = 1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfd2db945db646e2942792618fac9e62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created, explore it at https://c.app.hopsworks.ai:443/p/5322/models/headlines_sentiment_model/1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(name: 'headlines_sentiment_model', version: 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines_sentiment_model.save(model_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0df7331e7e812bfddd28e2aa81560e32bf86a4e5b79f907d6511c0dce318c93d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
